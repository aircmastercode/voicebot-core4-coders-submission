# Configuration for the P2P Lending Voice Bot

# ==============================================================================
# AWS Bedrock Configuration
# ==============================================================================
aws_bedrock:
  region: "us-east-1" # Replace with your AWS region if different
  knowledge_base:
    model_id: "anthropic.claude-3-sonnet-20240229-v1:0" # Foundational model for knowledge retrieval
    max_results: 3 # Number of search results to retrieve from the knowledge base

  response_generation:
    model_id: "anthropic.claude-3-haiku-20240307-v1:0" # Cost-effective and fast model for generating responses
    temperature: 0.7
    max_tokens: 500

# ==============================================================================
# API Gateway Configuration
# ==============================================================================
api_gateway:
  # The base URL should be stored in an environment variable (API_GATEWAY_URL)
  # Example: https://xxxxxxxxxx.execute-api.us-east-1.amazonaws.com/dev
  base_url: "https://9kti499scf.execute-api.us-west-2.amazonaws.com/dev"

  # The API key should be stored in an environment variable (API_GATEWAY_KEY)
  api_key: ""

  endpoints:
    nlp: "/nlp" # Endpoint for all NLP operations (intent, entities, knowledge base)

# ==============================================================================
# ASR (Automatic Speech Recognition) Configuration
# ==============================================================================
asr:
  model: "whisper-1" # OpenAI's Whisper model for speech recognition
  language: "en"     # Default language
  sample_rate: 16000 # Sample rate in Hz, 16kHz is optimal for Whisper
  silence_threshold: 0.03  # For silence detection
  continuous_mode: true    # Whether to use continuous listening mode

# ==============================================================================
# TTS (Text-to-Speech) Configuration
# ==============================================================================
tts:
  model: "tts-1"        # OpenAI's TTS model (options: tts-1, tts-1-hd)
  voice: "nova"         # Voice to use (options: alloy, echo, fable, onyx, nova, shimmer)
  output_format: "mp3"  # Output format
  speed: 1.0            # Speed multiplier (0.25 - 4.0)
  add_discourse_markers: true  # Add natural discourse markers like pauses and filler words

# ==============================================================================
# Logging Configuration
# ==============================================================================
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
